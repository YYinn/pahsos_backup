{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "1. Data folders preprocess\n",
    "2. Preprocess for segmentation\n",
    "3. Preprocess for classification\n",
    "--------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Folders preprocess\n",
    "由于每个人的文件夹中，包括多个序列，其中只有一个序列为本研究使用的序列，且该文件夹中带有分割的（.nii.gz）文件。\n",
    "\n",
    "    PAHSOS\n",
    "    |-- patient1_name\n",
    "        |--subfold1\n",
    "            |--seq1\n",
    "                |--xxxx.dcm\n",
    "                |--xxxx.dcm\n",
    "                |--patient1_name-SEG.nii.gz\n",
    "            |--seq2\n",
    "                |--xxxx.dcm\n",
    "                |--xxxx.dcm\n",
    "            |--seq3\n",
    "                |--xxxx.dcm\n",
    "                |--xxxx.dcm\n",
    "    BCs\n",
    "    HBV\n",
    "\n",
    "为了后续使用方便，首先对原始数据进行处理，只保留一个序列的数据（.dcm）和对应的分割文件(.nii.gz)。将原始数据（Raw/）重新保存（simple/）。处理后的文件格式如下所示：\n",
    "\n",
    "    PAHSOS\n",
    "    |-- patient1_name\n",
    "        |--xxxx.dcm\n",
    "        |--xxxx.dcm\n",
    "        |--patient1_name-SEG.nii.gz\n",
    "    BCs\n",
    "    HBV\n",
    "\n",
    "* 由于这里有两批数据，因此分别进行处理，首先存到/simple_1/中，然后合并，并删除排除的病例，得到最终的simple_data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess for auto-segmentation\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess data. \n",
    "save(rename) following nnunet instructor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跑了两次，第一次是所有数据，在/mnt/ExtData/workspace/pahsos/new_zhengzhou/segmentation/nnUNet_raw_data_base/nnUNet_raw_data/Task_LITS_ori。 \n",
    "\n",
    "后一次把更改了两个数据重新跑了，在/mnt/ExtData/workspace/pahsos/new_zhengzhou/segmentation/nnUNet_raw_data_base/nnUNet_raw_data/Task029_LITS。\n",
    "\n",
    "然后把第二次的结果(idx=1,5)的output（output2）重新命名，替换到output中。\n",
    "\n",
    "注意这里因为是从001开始命名的。因此对应的是002和006\n",
    "\n",
    "好的，又有一个数据有问题 。 再重新跑一次XUANYUAN这个 030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def read_dcm(path):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dcm_series = reader.GetGDCMSeriesFileNames(path)\n",
    "    reader.SetFileNames(dcm_series)\n",
    "    img = reader.Execute()\n",
    "    npy = sitk.GetArrayFromImage(img)\n",
    "    return img, npy\n",
    "\n",
    "def resample_to_spacing(npy_image, source_spacing, target_spacing, order=1):\n",
    "    scale = np.array(source_spacing) / np.array(target_spacing)\n",
    "    zoom_factor = np.array(target_spacing) / np.array(source_spacing)\n",
    "    target_npy_image = zoom(npy_image, scale, order=order)\n",
    "    return target_npy_image, zoom_factor, scale\n",
    "\n",
    "def change_axes_of_image(npy_image, orientation, reorientation=[1, 1, 1]):\n",
    "    if orientation[0] < 0:\n",
    "        npy_image = np.flip(npy_image, axis=0)\n",
    "        print('change_axes_of_image', orientation)\n",
    "    if orientation[1] < 0:\n",
    "        npy_image = np.flip(npy_image, axis=1)\n",
    "        print('change_axes_of_image', orientation)\n",
    "    if orientation[2] < 0:\n",
    "        npy_image = np.flip(npy_image, axis=2)\n",
    "        print('change_axes_of_image', orientation)\n",
    "    return npy_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINGKOU\n",
      "DINGXIZHENG\n",
      "FENGZHAOYIN\n",
      "GUORUANCHAO\n",
      "LIGUOQIANG\n",
      "LIJUN\n",
      "LILINGSHAN\n",
      "LIUXINMIN\n",
      "LIUXIUYU\n",
      "MALAN\n",
      "MAMEILING\n",
      "MENGXIANLIAN\n",
      "MIAOSHUQIN\n",
      "NIUSHUAN\n",
      "NIUSHUAN2\n",
      "SHIHAIXIA\n",
      "SUNYONGXIN\n",
      "SUNZHIQIANG\n",
      "TIANQUANWU\n",
      "WANGHAIXIN\n",
      "XUANYUAN\n",
      "loading 20/27 in folder GANDUAN2: XUANYUAN  spacing : [5.000006081891316, 0.984251976, 0.984251976] , direction : [1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.3/itkImageSeriesReader.hxx, line 477\n",
      "ImageSeriesReader (0x5586a032c3f0): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.0467142\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving files for XUANYUAN as /mnt/ExtData/workspace/pahsos/new_zhengzhou/segmentation/nnUNet_raw_data_base/nnUNet_raw_data/Task029_LITS/imagesTs/test_001_0000.nii.gz\n",
      "YANFENGCHAN\n",
      "YANGUOQIANG\n",
      "ZHANGCHANGHAI\n",
      "ZHANGGUANGCHAO\n",
      "ZHANGSHENGCAI\n",
      "ZHUYOULIANG\n"
     ]
    }
   ],
   "source": [
    "# 用于seg数据的整理\n",
    "'''\n",
    "_image_ori : 原图\n",
    "_image_aft_resample : 重采样后图\n",
    "_label_ori : 原始label\n",
    "_label_aft_resample : 重采样后的label。\n",
    "'''\n",
    "\n",
    "ori_img_path = '/media/yinn147/My Passport/2、血吡咯蛋白加合物联合影像组学诊断PAs-HSOS的诊断模型建立与评价（高老师医院课题）/郑州标注/'\n",
    "# nnunet_img_save_path = '/mnt/ExtData/workspace/pahsos/new_zhengzhou/segmentation/nnUNet_raw_data_base/nnUNet_raw_data/Task029_LITS/imagesTs'\n",
    "nnunet_img_save_path = '/mnt/ExtData/workspace/pahsos/new_zhengzhou/segmentation/nnUNet_raw_data_base/nnUNet_raw_data/Task029_LITS/imagesTs'\n",
    "n = ['GANDUAN2']#, '111FANDE', 'ganduan']\n",
    "cnt = 1\n",
    "for subfolder in n:\n",
    "    disease_cls_path = os.path.join(ori_img_path, f'{subfolder}/') \n",
    "    patients_path = glob.glob(os.path.join(disease_cls_path, '*'))\n",
    "\n",
    "    for i, patient_path in enumerate(patients_path):\n",
    "\n",
    "        patient_name = patient_path[patient_path.rfind('/')+1:]\n",
    "        dcm_path = glob.glob(os.path.join(patient_path, '*/'))[0]\n",
    "        print(patient_name)\n",
    "\n",
    "        # if patient_name not in ('XUANYUAN'):\n",
    "        #     continue\n",
    "\n",
    "        \n",
    "    #     # load img\n",
    "        img, npy_img = read_dcm(dcm_path)\n",
    "\n",
    "        # load info\n",
    "        spacing = list(reversed(img.GetSpacing()))\n",
    "        direction = img.GetDirection()\n",
    "        direction = [direction[8], direction[4], direction[0]]\n",
    "\n",
    "        print(f'loading {i}/{len(patients_path)} in folder {subfolder}: {patient_name}  spacing : {spacing} , direction : {direction}')\n",
    "        \n",
    "        # preprocess img : resample, reorientation\n",
    "        aft_image, _, _ = resample_to_spacing(npy_img, spacing, [1, 1, 1])\n",
    "        aft_image = change_axes_of_image(aft_image, direction, [1, 1, 1])\n",
    "        nii_block = sitk.GetImageFromArray(aft_image)\n",
    "       \n",
    "\n",
    "        # save to required format\n",
    "        if cnt<10:\n",
    "            file_name = os.path.join(nnunet_img_save_path, f'test_00{cnt}_0000.nii.gz')\n",
    "        elif cnt<100:\n",
    "            file_name = os.path.join(nnunet_img_save_path, f'test_0{cnt}_0000.nii.gz')\n",
    "        else:\n",
    "            file_name = os.path.join(nnunet_img_save_path, f'test_{cnt}_0000.nii.gz')\n",
    "\n",
    "        cnt += 1\n",
    "        out = sitk.WriteImage(nii_block, file_name)\n",
    "        print(f'saving files for {patient_name} as {file_name}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess for classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. reorientate & resample\n",
    "\n",
    "- ori_data : /mnt/ExtData/pahsos/Data/simple_data\n",
    "\n",
    "- 将处理后的图像和label保存成npy格式， /mnt/ExtData/pahsos/Data/preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import glob\n",
    "import os\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "# def change_label(label):\n",
    "#     '''seperate label 10 into 10, 11, 12'''\n",
    "\n",
    "#     temp_label_10 = np.argwhere(label==10)\n",
    "#     # print(len(temp_label_10))\n",
    "\n",
    "#     x_range = np.unique(np.argwhere(label==10)[:, 0])\n",
    "#     y_range = np.unique(np.argwhere(label==10)[:, 1])\n",
    "#     z_range = np.unique(np.argwhere(label==10)[:, 2])\n",
    "#     flag = 0\n",
    "#     for range_unique in x_range, y_range, z_range:\n",
    "#         if range_unique.shape[0] == 9:\n",
    "#             # check\n",
    "#             if range_unique[0] == range_unique[1]-1 == range_unique[2]-2 and range_unique[3] == range_unique[4]-1 == range_unique[5]-2 and range_unique[6] == range_unique[7]-1 == range_unique[8]-2:\n",
    "#                 if range_unique is x_range:\n",
    "#                     temp_label_10 = temp_label_10[temp_label_10[:,0].argsort()]\n",
    "#                 elif range_unique is y_range:\n",
    "#                     temp_label_10 = temp_label_10[temp_label_10[:,1].argsort()]\n",
    "#                 else:\n",
    "#                     temp_label_10 = temp_label_10[temp_label_10[:,2].argsort()]\n",
    "\n",
    "#                 for m in range(0, 27):\n",
    "                    \n",
    "#                     label[temp_label_10[27+m][0], temp_label_10[27+m][1], temp_label_10[27+m][2]] = 11\n",
    "#                     label[temp_label_10[54+m][0], temp_label_10[54+m][1], temp_label_10[54+m][2]] = 12\n",
    "#                 flag = 1\n",
    "#                 break\n",
    "#     if flag == 0:\n",
    "#         print('NO!')\n",
    "#     return label  \n",
    "\n",
    "\n",
    "def change_label_spe(label, patient_name):\n",
    "    '''seperate label 10 into 10, 11, 12'''\n",
    "\n",
    "    temp_label_10 = np.argwhere(label==10)\n",
    "    # print(len(temp_label_10))\n",
    "\n",
    "    x_range = np.unique(np.argwhere(label==10)[:, 0])\n",
    "    y_range = np.unique(np.argwhere(label==10)[:, 1])\n",
    "    z_range = np.unique(np.argwhere(label==10)[:, 2])\n",
    "    flag = 0\n",
    "    if (patient_name in ('LILINGSHAN', 'MENGXIANLIAN', 'SUNZHIQIANG', 'WANGHAIXIN')):\n",
    "        if patient_name == 'LILINGSHAN':\n",
    "            center = [[44, 222, 245], [44, 227, 220], [44, 262, 198]]\n",
    "        elif patient_name == 'MENGXIANLIAN':\n",
    "            center = [[87, 261, 238], [87, 255, 219], [86, 272, 191]]\n",
    "        elif patient_name == 'SUNZHIQIANG':\n",
    "            center = [[39, 250, 245], [38, 282, 211], [38, 263, 217]]\n",
    "        elif patient_name == 'WANGHAIXIN':\n",
    "            center = [[92, 264, 197], [92, 242, 210], [92, 238, 230]]\n",
    "        else:\n",
    "            print('WRONG LABEL!!')\n",
    "\n",
    "        label[label == 10] = 0\n",
    "\n",
    "        c = center[0]\n",
    "        label[c[0] - 1: c[0] + 2, c[1] - 1: c[1] + 2, c[2] - 1: c[2] + 2] = 10\n",
    "        c = center[1]\n",
    "        label[c[0] - 1: c[0] + 2, c[1] - 1: c[1] + 2, c[2] - 1: c[2] + 2] = 11\n",
    "        c = center[2]\n",
    "        label[c[0] - 1: c[0] + 2, c[1] - 1: c[1] + 2, c[2] - 1: c[2] + 2] = 12\n",
    "        flag = 1\n",
    "    else:\n",
    "        for range_unique in x_range, y_range, z_range:\n",
    "            if range_unique.shape[0] == 9:\n",
    "                # check\n",
    "                if range_unique[0] == range_unique[1]-1 == range_unique[2]-2 and range_unique[3] == range_unique[4]-1 == range_unique[5]-2 and range_unique[6] == range_unique[7]-1 == range_unique[8]-2:\n",
    "                    if range_unique is x_range:\n",
    "                        temp_label_10 = temp_label_10[temp_label_10[:,0].argsort()]\n",
    "                    elif range_unique is y_range:\n",
    "                        temp_label_10 = temp_label_10[temp_label_10[:,1].argsort()]\n",
    "                    else:\n",
    "                        temp_label_10 = temp_label_10[temp_label_10[:,2].argsort()]\n",
    "\n",
    "                    for m in range(0, 27):\n",
    "                        \n",
    "                        label[temp_label_10[27+m][0], temp_label_10[27+m][1], temp_label_10[27+m][2]] = 11\n",
    "                        label[temp_label_10[54+m][0], temp_label_10[54+m][1], temp_label_10[54+m][2]] = 12\n",
    "                    flag = 1\n",
    "                    break\n",
    "    if flag == 0:\n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!!!!!!! WRONG LABEL !!!!!!!!!!!!!!!!!!!!!!!!!! ')\n",
    "    return label  \n",
    "\n",
    "def read_dcm(path):\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dcm_series = reader.GetGDCMSeriesFileNames(path)\n",
    "    reader.SetFileNames(dcm_series)\n",
    "    img = reader.Execute()\n",
    "    npy = sitk.GetArrayFromImage(img)\n",
    "    return img, npy\n",
    "\n",
    "\n",
    "def resample_to_spacing(npy_image, source_spacing, target_spacing, order=1):\n",
    "    scale = np.array(source_spacing) / np.array(target_spacing)\n",
    "    zoom_factor = np.array(target_spacing) / np.array(source_spacing)\n",
    "    target_npy_image = zoom(npy_image, scale, order=order)\n",
    "    return target_npy_image, zoom_factor, scale\n",
    "\n",
    "def change_axes_of_image(npy_image, orientation, reorientation=[1, 1, 1]):\n",
    "    if orientation[0] < 0:\n",
    "        npy_image = np.flip(npy_image, axis=0)\n",
    "    if orientation[1] < 0:\n",
    "        npy_image = np.flip(npy_image, axis=1)\n",
    "    if orientation[2] < 0:\n",
    "        npy_image = np.flip(npy_image, axis=2)\n",
    "    return npy_image\n",
    "\n",
    "def resample_mask_to_spacing(npy_mask, source_spacing, target_spacing, num_label, order=1):\n",
    "    # print('resampling mask')\n",
    "    scale = np.array(source_spacing) / np.array(target_spacing)\n",
    "    zoom_factor = np.array(target_spacing) / np.array(source_spacing)\n",
    "    target_npy_mask = np.zeros_like(npy_mask)\n",
    "    target_npy_mask = zoom(target_npy_mask, scale, order=order)\n",
    "    # print(np.unique(npy_mask))\n",
    "    for i in range(1, num_label + 1):\n",
    "        # print(i)\n",
    "        current_mask = npy_mask.copy()\n",
    "\n",
    "        current_mask[current_mask != i] = 0\n",
    "        current_mask[current_mask == i] = 1\n",
    "        # print(len(np.argwhere(current_mask!=0)))\n",
    "\n",
    "        current_mask = zoom(current_mask, scale, order=order)\n",
    "        current_mask = (current_mask > 0.5).astype(np.uint8)\n",
    "        # print(len(np.argwhere(current_mask!=0)))\n",
    "        target_npy_mask[current_mask != 0] = i\n",
    "    return target_npy_mask, zoom_factor, scale"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里发现有四个人len(np.argwhere(label == 10)) != 81 ,先对这几个人做一下修正。\n",
    "这里先看一下这四个人的，然后把这些调整添加到change_label函数中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 85, 271, 190],\n",
       "       [ 85, 271, 191],\n",
       "       [ 85, 271, 192],\n",
       "       [ 85, 272, 190],\n",
       "       [ 85, 272, 191],\n",
       "       [ 85, 272, 192],\n",
       "       [ 85, 273, 190],\n",
       "       [ 85, 273, 191],\n",
       "       [ 85, 273, 192],\n",
       "       [ 86, 254, 218],\n",
       "       [ 86, 254, 219],\n",
       "       [ 86, 254, 220],\n",
       "       [ 86, 255, 218],\n",
       "       [ 86, 255, 219],\n",
       "       [ 86, 255, 220],\n",
       "       [ 86, 256, 218],\n",
       "       [ 86, 256, 219],\n",
       "       [ 86, 256, 220],\n",
       "       [ 86, 260, 237],\n",
       "       [ 86, 260, 238],\n",
       "       [ 86, 260, 239],\n",
       "       [ 86, 261, 237],\n",
       "       [ 86, 261, 238],\n",
       "       [ 86, 261, 239],\n",
       "       [ 86, 262, 237],\n",
       "       [ 86, 262, 238],\n",
       "       [ 86, 262, 239],\n",
       "       [ 86, 271, 190],\n",
       "       [ 86, 271, 191],\n",
       "       [ 86, 271, 192],\n",
       "       [ 86, 272, 190],\n",
       "       [ 86, 272, 191],\n",
       "       [ 86, 272, 192],\n",
       "       [ 86, 273, 190],\n",
       "       [ 86, 273, 191],\n",
       "       [ 86, 273, 192],\n",
       "       [ 87, 254, 218],\n",
       "       [ 87, 254, 219],\n",
       "       [ 87, 254, 220],\n",
       "       [ 87, 255, 218],\n",
       "       [ 87, 255, 219],\n",
       "       [ 87, 255, 220],\n",
       "       [ 87, 256, 218],\n",
       "       [ 87, 256, 219],\n",
       "       [ 87, 256, 220],\n",
       "       [ 87, 260, 237],\n",
       "       [ 87, 260, 238],\n",
       "       [ 87, 260, 239],\n",
       "       [ 87, 261, 237],\n",
       "       [ 87, 261, 238],\n",
       "       [ 87, 261, 239],\n",
       "       [ 87, 262, 237],\n",
       "       [ 87, 262, 238],\n",
       "       [ 87, 262, 239],\n",
       "       [ 87, 271, 190],\n",
       "       [ 87, 271, 191],\n",
       "       [ 87, 271, 192],\n",
       "       [ 87, 272, 190],\n",
       "       [ 87, 272, 191],\n",
       "       [ 87, 272, 192],\n",
       "       [ 87, 273, 190],\n",
       "       [ 87, 273, 191],\n",
       "       [ 87, 273, 192],\n",
       "       [ 88, 254, 218],\n",
       "       [ 88, 254, 219],\n",
       "       [ 88, 254, 220],\n",
       "       [ 88, 255, 218],\n",
       "       [ 88, 255, 219],\n",
       "       [ 88, 255, 220],\n",
       "       [ 88, 256, 218],\n",
       "       [ 88, 256, 219],\n",
       "       [ 88, 256, 220],\n",
       "       [ 88, 260, 237],\n",
       "       [ 88, 260, 238],\n",
       "       [ 88, 260, 239],\n",
       "       [ 88, 261, 237],\n",
       "       [ 88, 261, 238],\n",
       "       [ 88, 261, 239],\n",
       "       [ 88, 262, 237],\n",
       "       [ 88, 262, 238],\n",
       "       [ 88, 262, 239],\n",
       "       [ 88, 266, 192],\n",
       "       [ 88, 266, 193],\n",
       "       [ 88, 266, 194],\n",
       "       [ 88, 267, 192],\n",
       "       [ 88, 267, 193],\n",
       "       [ 88, 267, 194],\n",
       "       [ 88, 268, 192],\n",
       "       [ 88, 268, 193],\n",
       "       [ 88, 268, 194]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "看了itksnap，基本是有些误触，以下是修正后的三个点的中心\n",
    "# a = sitk.GetArrayFromImage(sitk.ReadImage('/media/yinn147/My Passport/2、血吡咯蛋白加合物联合影像组学诊断PAs-HSOS的诊断模型建立与评价（高老师医院课题）/郑州标注/GANDUAN2/LILINGSHAN/LILINGSHAN.nii.gz'))\n",
    "#[ 44, 222, 245], [44, 227, 220], [44, 262, 198]\n",
    "a = sitk.GetArrayFromImage(sitk.ReadImage('/media/yinn147/My Passport/2、血吡咯蛋白加合物联合影像组学诊断PAs-HSOS的诊断模型建立与评价（高老师医院课题）/郑州标注/GANDUAN2/MENGXIANLIAN/MENGXIANLIAN.nii.gz'))\n",
    "# [87, 261, 238], [87, 255, 219], [86, 272, 191]\n",
    "# a = sitk.GetArrayFromImage(sitk.ReadImage('/media/yinn147/My Passport/2、血吡咯蛋白加合物联合影像组学诊断PAs-HSOS的诊断模型建立与评价（高老师医院课题）/郑州标注/GANDUAN2/SUNZHIQIANG/SUNZHIQIANG.nii'))\n",
    "# [39, 250, 245]  [38, 282, 211], [38, 263, 217]\n",
    "# a = sitk.GetArrayFromImage(sitk.ReadImage('/media/yinn147/My Passport/2、血吡咯蛋白加合物联合影像组学诊断PAs-HSOS的诊断模型建立与评价（高老师医院课题）/郑州标注/GANDUAN2/WANGHAIXIN/WANGHAIXIN.nii'))\n",
    "# [92, 264, 197], [92, 242, 210], [92, 238, 230]\n",
    "\n",
    "# np.argwhere(a == 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LILINGSHAN 87 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "27 27 27\n",
      "MENGXIANLIAN 90 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "27 27 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.3/itkImageSeriesReader.hxx, line 477\n",
      "ImageSeriesReader (0x55869adb3df0): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000987952\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUNZHIQIANG 82 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "27 27 27\n",
      "WANGHAIXIN 90 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "27 27 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.3/itkImageSeriesReader.hxx, line 477\n",
      "ImageSeriesReader (0x55869adb3df0): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.0467142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def change_label_spe(label, patient_name):\n",
    "    '''seperate label 10 into 10, 11, 12'''\n",
    "\n",
    "    temp_label_10 = np.argwhere(label==10)\n",
    "    # print(len(temp_label_10))\n",
    "\n",
    "    x_range = np.unique(np.argwhere(label==10)[:, 0])\n",
    "    y_range = np.unique(np.argwhere(label==10)[:, 1])\n",
    "    z_range = np.unique(np.argwhere(label==10)[:, 2])\n",
    "    flag = 0\n",
    "    if (patient_name in ('LILINGSHAN', 'MENGXIANLIAN', 'SUNZHIQIANG', 'WANGHAIXIN')):\n",
    "        if patient_name == 'LILINGSHAN':\n",
    "            center = [[44, 222, 245], [44, 227, 220], [44, 262, 198]]\n",
    "        elif patient_name == 'MENGXIANLIAN':\n",
    "            center = [[87, 261, 238], [87, 255, 219], [86, 272, 191]]\n",
    "        elif patient_name == 'SUNZHIQIANG':\n",
    "            center = [[39, 250, 245], [38, 282, 211], [38, 263, 217]]\n",
    "        elif patient_name == 'WANGHAIXIN':\n",
    "            center = [[92, 264, 197], [92, 242, 210], [92, 238, 230]]\n",
    "        else:\n",
    "            print('WRONG LABEL!!')\n",
    "\n",
    "        label[label == 10] = 0\n",
    "\n",
    "        c = center[0]\n",
    "        label[c[0] - 1: c[0] + 2, c[1] - 1: c[1] + 2, c[2] - 1: c[2] + 2] = 10\n",
    "        c = center[1]\n",
    "        label[c[0] - 1: c[0] + 2, c[1] - 1: c[1] + 2, c[2] - 1: c[2] + 2] = 11\n",
    "        c = center[2]\n",
    "        label[c[0] - 1: c[0] + 2, c[1] - 1: c[1] + 2, c[2] - 1: c[2] + 2] = 12\n",
    "        flag = 1\n",
    "    else:\n",
    "        for range_unique in x_range, y_range, z_range:\n",
    "            if range_unique.shape[0] == 9:\n",
    "                # check\n",
    "                if range_unique[0] == range_unique[1]-1 == range_unique[2]-2 and range_unique[3] == range_unique[4]-1 == range_unique[5]-2 and range_unique[6] == range_unique[7]-1 == range_unique[8]-2:\n",
    "                    if range_unique is x_range:\n",
    "                        temp_label_10 = temp_label_10[temp_label_10[:,0].argsort()]\n",
    "                    elif range_unique is y_range:\n",
    "                        temp_label_10 = temp_label_10[temp_label_10[:,1].argsort()]\n",
    "                    else:\n",
    "                        temp_label_10 = temp_label_10[temp_label_10[:,2].argsort()]\n",
    "\n",
    "                    for m in range(0, 27):\n",
    "                        \n",
    "                        label[temp_label_10[27+m][0], temp_label_10[27+m][1], temp_label_10[27+m][2]] = 11\n",
    "                        label[temp_label_10[54+m][0], temp_label_10[54+m][1], temp_label_10[54+m][2]] = 12\n",
    "                    flag = 1\n",
    "                    break\n",
    "    if flag == 0:\n",
    "        print('!!!!!!!!!!!!!!!!!!!!!!!!!!!! WRONG LABEL !!!!!!!!!!!!!!!!!!!!!!!!!! ')\n",
    "    return label  \n",
    "\n",
    "\n",
    "ori_img_path = '/media/yinn147/My Passport/2、血吡咯蛋白加合物联合影像组学诊断PAs-HSOS的诊断模型建立与评价（高老师医院课题）/郑州标注/'\n",
    "save_path = '/mnt/ExtData/workspace/pahsos/new_zhengzhou/processed'\n",
    "n = ['GANDUAN2', '111FANDE', 'ganduan']\n",
    "cnt = 1\n",
    "for subfolder in n:\n",
    "    disease_cls_path = os.path.join(ori_img_path, f'{subfolder}/') \n",
    "    patients_path = glob.glob(os.path.join(disease_cls_path, '*'))\n",
    "\n",
    "    for i, patient_path in enumerate(patients_path):\n",
    "\n",
    "        patient_name = patient_path[patient_path.rfind('/')+1:]\n",
    "        dcm_path = glob.glob(os.path.join(patient_path, '*/'))[0]\n",
    "        # print('path', patient_name, patient_path)\n",
    "\n",
    "        patient_save_path = os.path.join(save_path, patient_name)\n",
    "        if not os.path.exists(patient_save_path):\n",
    "            os.makedirs(patient_save_path)\n",
    "\n",
    "        # load img\n",
    "        img, npy_img = read_dcm(dcm_path)\n",
    "        # load label\n",
    "        label_path = glob.glob(os.path.join(patient_path, '*.nii*'))[0]\n",
    "        if len(label_path) == 0:\n",
    "            print(f'cant find label for patient {patient_name}')\n",
    "        # npy_label = sitk.GetArrayFromImage(sitk.ReadImage(label_path))\n",
    "        ## 因为郑州数据的label有的是nii有的是nii.gz 所以这里用nilabel读\n",
    "        npy_label = nib.load(label_path).get_fdata()\n",
    "        npy_label = npy_label.transpose(2, 1, 0)\n",
    "\n",
    "\n",
    "        if npy_img.shape == npy_label.shape:\n",
    "            ## for additional \n",
    "            if not (patient_name in ('LILINGSHAN', 'MENGXIANLIAN', 'SUNZHIQIANG', 'WANGHAIXIN')):\n",
    "                continue\n",
    "            # #load img info\n",
    "            spacing = list(reversed(img.GetSpacing()))\n",
    "            direction = img.GetDirection()\n",
    "            direction = [direction[8], direction[4], direction[0]]\n",
    "\n",
    "            # change label 10 into 10, 11, 12\n",
    "            if len(np.argwhere(npy_label == 10)) != 81:\n",
    "                print(patient_name, len(np.argwhere(npy_label == 10)), np.unique(npy_label))\n",
    "            npy_label = change_label_spe(npy_label, patient_name)\n",
    "\n",
    "            ## check效果！！\n",
    "            print(len(np.argwhere(npy_label == 10)), len(np.argwhere(npy_label == 11)), len(np.argwhere(npy_label == 12)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 0/27 : DINGKOU  spacing : [5.0, 0.804688, 0.804688] , direction : [1.0, 1.0, 1.0], (130, 512, 512), (130, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 333 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (650, 412, 412)\n",
      "🔵 0 / 27 processing and saving npy files : GANDUAN2 - DINGKOU\n",
      "loading 1/27 : DINGXIZHENG  spacing : [5.0, 0.712890625, 0.712890625] , direction : [1.0, 1.0, 1.0], (78, 512, 512), (78, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (390, 365, 365)\n",
      "🔵 1 / 27 processing and saving npy files : GANDUAN2 - DINGXIZHENG\n",
      "loading 2/27 : FENGZHAOYIN  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (77, 512, 512), (77, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (385, 500, 500)\n",
      "🔵 2 / 27 processing and saving npy files : GANDUAN2 - FENGZHAOYIN\n",
      "loading 3/27 : GUORUANCHAO  spacing : [5.0, 0.782, 0.782] , direction : [1.0, 1.0, 1.0], (54, 512, 512), (54, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (270, 400, 400)\n",
      "🔵 3 / 27 processing and saving npy files : GANDUAN2 - GUORUANCHAO\n",
      "loading 4/27 : LIGUOQIANG  spacing : [5.0, 0.976563, 0.976563] , direction : [1.0, 1.0, 1.0], (81, 512, 512), (81, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (405, 500, 500)\n",
      "🔵 4 / 27 processing and saving npy files : GANDUAN2 - LIGUOQIANG\n",
      "loading 5/27 : LIJUN  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (94, 512, 512), (94, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (470, 500, 500)\n",
      "🔵 5 / 27 processing and saving npy files : GANDUAN2 - LIJUN\n",
      "loading 6/27 : LILINGSHAN  spacing : [5.0, 0.781, 0.781] , direction : [1.0, 1.0, 1.0], (60, 512, 512), (60, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (300, 400, 400)\n",
      "🔵 6 / 27 processing and saving npy files : GANDUAN2 - LILINGSHAN\n",
      "loading 7/27 : LIUXINMIN  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (71, 512, 512), (71, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (355, 500, 500)\n",
      "🔵 7 / 27 processing and saving npy files : GANDUAN2 - LIUXINMIN\n",
      "loading 8/27 : LIUXIUYU  spacing : [5.0, 0.910156, 0.910156] , direction : [1.0, 1.0, 1.0], (82, 512, 512), (82, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (410, 466, 466)\n",
      "🔵 8 / 27 processing and saving npy files : GANDUAN2 - LIUXIUYU\n",
      "loading 9/27 : MALAN  spacing : [5.0, 0.73828125, 0.73828125] , direction : [1.0, 1.0, 1.0], (45, 512, 512), (45, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (225, 378, 378)\n",
      "🔵 9 / 27 processing and saving npy files : GANDUAN2 - MALAN\n",
      "loading 10/27 : MAMEILING  spacing : [5.0, 0.9765625, 0.9765625] , direction : [1.0, 1.0, 1.0], (66, 512, 512), (66, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (330, 500, 500)\n",
      "🔵 10 / 27 processing and saving npy files : GANDUAN2 - MAMEILING\n",
      "loading 11/27 : MENGXIANLIAN  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (99, 512, 512), (99, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (495, 500, 500)\n",
      "🔵 11 / 27 processing and saving npy files : GANDUAN2 - MENGXIANLIAN\n",
      "loading 12/27 : MIAOSHUQIN  spacing : [5.0, 0.972, 0.972] , direction : [1.0, 1.0, 1.0], (127, 512, 512), (127, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (635, 498, 498)\n",
      "🔵 12 / 27 processing and saving npy files : GANDUAN2 - MIAOSHUQIN\n",
      "loading 13/27 : NIUSHUAN  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (57, 512, 512), (57, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (285, 500, 500)\n",
      "🔵 13 / 27 processing and saving npy files : GANDUAN2 - NIUSHUAN\n",
      "loading 14/27 : NIUSHUAN2  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (135, 512, 512), (135, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (675, 500, 500)\n",
      "🔵 14 / 27 processing and saving npy files : GANDUAN2 - NIUSHUAN2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.3/itkImageSeriesReader.hxx, line 477\n",
      "ImageSeriesReader (0x55869cb7cef0): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.000987952\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 15/27 : SHIHAIXIA  spacing : [4.999987951807229, 0.919922, 0.919922] , direction : [1.0, 1.0, 1.0], (84, 512, 512), (84, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (420, 471, 471)\n",
      "🔵 15 / 27 processing and saving npy files : GANDUAN2 - SHIHAIXIA\n",
      "loading 16/27 : SUNYONGXIN  spacing : [4.999998063492061, 0.78125, 0.78125] , direction : [1.0, 1.0, 1.0], (64, 512, 512), (64, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (320, 400, 400)\n",
      "🔵 16 / 27 processing and saving npy files : GANDUAN2 - SUNYONGXIN\n",
      "loading 17/27 : SUNZHIQIANG  spacing : [5.0, 0.782, 0.782] , direction : [1.0, 1.0, 1.0], (46, 512, 512), (46, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 328 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (230, 400, 400)\n",
      "🔵 17 / 27 processing and saving npy files : GANDUAN2 - SUNZHIQIANG\n",
      "loading 18/27 : TIANQUANWU  spacing : [5.0, 0.896484375, 0.896484375] , direction : [1.0, 1.0, 1.0], (60, 512, 512), (60, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (300, 459, 459)\n",
      "🔵 18 / 27 processing and saving npy files : GANDUAN2 - TIANQUANWU\n",
      "loading 19/27 : WANGHAIXIN  spacing : [5.0, 0.76171875, 0.76171875] , direction : [1.0, 1.0, 1.0], (132, 512, 512), (132, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (660, 390, 390)\n",
      "🔵 19 / 27 processing and saving npy files : GANDUAN2 - WANGHAIXIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: In /tmp/SimpleITK-build/ITK-prefix/include/ITK-5.3/itkImageSeriesReader.hxx, line 477\n",
      "ImageSeriesReader (0x55869cb7cef0): Non uniform sampling or missing slices detected,  maximum nonuniformity:0.0467142\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 20/27 : XUANYUAN  spacing : [5.000006081891316, 0.984251976, 0.984251976] , direction : [1.0, 1.0, 1.0], (94, 508, 508), (94, 508, 508)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (470, 500, 500)\n",
      "🔵 20 / 27 processing and saving npy files : GANDUAN2 - XUANYUAN\n",
      "loading 21/27 : YANFENGCHAN  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (96, 512, 512), (96, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (480, 500, 500)\n",
      "🔵 21 / 27 processing and saving npy files : GANDUAN2 - YANFENGCHAN\n",
      "loading 22/27 : YANGUOQIANG  spacing : [5.0, 0.890625, 0.890625] , direction : [1.0, 1.0, 1.0], (148, 512, 512), (148, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (740, 456, 456)\n",
      "🔵 22 / 27 processing and saving npy files : GANDUAN2 - YANGUOQIANG\n",
      "loading 23/27 : ZHANGCHANGHAI  spacing : [5.0, 0.781, 0.781] , direction : [1.0, 1.0, 1.0], (129, 512, 512), (129, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (645, 400, 400)\n",
      "🔵 23 / 27 processing and saving npy files : GANDUAN2 - ZHANGCHANGHAI\n",
      "loading 24/27 : ZHANGGUANGCHAO  spacing : [5.0, 0.839, 0.839] , direction : [1.0, 1.0, 1.0], (49, 512, 512), (49, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (245, 430, 430)\n",
      "🔵 24 / 27 processing and saving npy files : GANDUAN2 - ZHANGGUANGCHAO\n",
      "loading 25/27 : ZHANGSHENGCAI  spacing : [5.0, 0.75390625, 0.75390625] , direction : [1.0, 1.0, 1.0], (61, 512, 512), (61, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (305, 386, 386)\n",
      "🔵 25 / 27 processing and saving npy files : GANDUAN2 - ZHANGSHENGCAI\n",
      "loading 26/27 : ZHUYOULIANG  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (61, 512, 512), (61, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (305, 500, 500)\n",
      "🔵 26 / 27 processing and saving npy files : GANDUAN2 - ZHUYOULIANG\n",
      "loading 0/9 : GUOJINLIANG  spacing : [5.180001392857142, 0.787401557, 0.787401557] , direction : [1.0, 1.0, 1.0], (57, 508, 508), (57, 508, 508)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (295, 400, 400)\n",
      "🔵 0 / 9 processing and saving npy files : 111FANDE - GUOJINLIANG\n",
      "loading 1/9 : LUFENGDE  spacing : [6.302616660714286, 0.787401557, 0.787401557] , direction : [1.0, 1.0, 1.0], (57, 508, 508), (57, 508, 508)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (359, 400, 400)\n",
      "🔵 1 / 9 processing and saving npy files : 111FANDE - LUFENGDE\n",
      "loading 2/9 : NIUSHUAN3  spacing : [5.350000007272727, 0.984251976, 0.984251976] , direction : [1.0, 1.0, 1.0], (56, 508, 508), (56, 508, 508)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (300, 500, 500)\n",
      "🔵 2 / 9 processing and saving npy files : 111FANDE - NIUSHUAN3\n",
      "loading 3/9 : WANGXIAOHUA  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (98, 512, 512), (98, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (490, 500, 500)\n",
      "🔵 3 / 9 processing and saving npy files : 111FANDE - WANGXIAOHUA\n",
      "loading 4/9 : XIAOJINZHONG  spacing : [5.0, 0.782, 0.782] , direction : [1.0, 1.0, 1.0], (58, 512, 512), (58, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (290, 400, 400)\n",
      "🔵 4 / 9 processing and saving npy files : 111FANDE - XIAOJINZHONG\n",
      "loading 5/9 : XIEDONGMEI  spacing : [5.729998218181816, 0.78125, 0.78125] , direction : [1.0, 1.0, 1.0], (56, 512, 512), (56, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (321, 400, 400)\n",
      "🔵 5 / 9 processing and saving npy files : 111FANDE - XIEDONGMEI\n",
      "loading 6/9 : XIETAO  spacing : [5.0, 0.97265625, 0.97265625] , direction : [1.0, 1.0, 1.0], (49, 512, 512), (49, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (245, 498, 498)\n",
      "🔵 6 / 9 processing and saving npy files : 111FANDE - XIETAO\n",
      "loading 7/9 : XUPENGPENG  spacing : [5.0, 0.935547, 0.935547] , direction : [1.0, 1.0, 1.0], (95, 512, 512), (95, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (475, 479, 479)\n",
      "🔵 7 / 9 processing and saving npy files : 111FANDE - XUPENGPENG\n",
      "loading 8/9 : ZHANGXIUHUA  spacing : [6.909998672727269, 1.082677126, 1.082677126] , direction : [1.0, 1.0, 1.0], (56, 508, 508), (56, 508, 508)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (387, 550, 550)\n",
      "🔵 8 / 9 processing and saving npy files : 111FANDE - ZHANGXIUHUA\n",
      "loading 0/12 : CHENGUITANG  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (104, 512, 512), (104, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 333 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (520, 500, 500)\n",
      "🔵 0 / 12 processing and saving npy files : ganduan - CHENGUITANG\n",
      "loading 1/12 : FANGJIALI  spacing : [5.0, 0.746094, 0.746094] , direction : [1.0, 1.0, 1.0], (51, 512, 512), (51, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 336 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (255, 382, 382)\n",
      "🔵 1 / 12 processing and saving npy files : ganduan - FANGJIALI\n",
      "loading 2/12 : HANTIEZHU  spacing : [5.0, 0.68359375, 0.68359375] , direction : [1.0, 1.0, 1.0], (128, 512, 512), (128, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (640, 350, 350)\n",
      "🔵 2 / 12 processing and saving npy files : ganduan - HANTIEZHU\n",
      "loading 3/12 : JINYUEE  spacing : [4.999999999999999, 0.837890625, 0.837890625] , direction : [1.0, 1.0, 1.0], (83, 512, 512), (83, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (415, 429, 429)\n",
      "🔵 3 / 12 processing and saving npy files : ganduan - JINYUEE\n",
      "loading 4/12 : LIQINGXI  spacing : [5.0, 0.976562, 0.976562] , direction : [1.0, 1.0, 1.0], (105, 512, 512), (105, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (525, 500, 500)\n",
      "🔵 4 / 12 processing and saving npy files : ganduan - LIQINGXI\n",
      "loading 5/12 : OUXIANCHEN  spacing : [4.999999999999999, 0.84375, 0.84375] , direction : [0.9999999999999867, 0.9999999999999867, 1.0], (144, 512, 512), (144, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (720, 432, 432)\n",
      "🔵 5 / 12 processing and saving npy files : ganduan - OUXIANCHEN\n",
      "loading 6/12 : SHIHEWANG  spacing : [5.0, 0.782, 0.782] , direction : [1.0, 1.0, 1.0], (142, 512, 512), (142, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (710, 400, 400)\n",
      "🔵 6 / 12 processing and saving npy files : ganduan - SHIHEWANG\n",
      "loading 7/12 : TONGNANGZI  spacing : [5.0, 0.8203125, 0.8203125] , direction : [1.0, 1.0, 1.0], (141, 512, 512), (141, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (705, 420, 420)\n",
      "🔵 7 / 12 processing and saving npy files : ganduan - TONGNANGZI\n",
      "loading 8/12 : YANXIAN  spacing : [5.0, 0.9765625, 0.9765625] , direction : [1.0, 1.0, 1.0], (85, 512, 512), (85, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (425, 500, 500)\n",
      "🔵 8 / 12 processing and saving npy files : ganduan - YANXIAN\n",
      "loading 9/12 : YUANGONGXIAN  spacing : [5.0, 0.782, 0.782] , direction : [1.0, 1.0, 1.0], (133, 512, 512), (133, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (665, 400, 400)\n",
      "🔵 9 / 12 processing and saving npy files : ganduan - YUANGONGXIAN\n",
      "loading 10/12 : ZHANGQINGTAO  spacing : [5.0, 0.89453125, 0.89453125] , direction : [1.0, 1.0, 1.0], (125, 512, 512), (125, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (625, 458, 458)\n",
      "🔵 10 / 12 processing and saving npy files : ganduan - ZHANGQINGTAO\n",
      "loading 11/12 : ZHANGTINGLIN  spacing : [5.0, 0.84765625, 0.84765625] , direction : [1.0, 1.0, 1.0], (45, 512, 512), (45, 512, 512)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] 324 [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.] (225, 434, 434)\n",
      "🔵 11 / 12 processing and saving npy files : ganduan - ZHANGTINGLIN\n"
     ]
    }
   ],
   "source": [
    "# 读取dcm文件 处理图像及勾画，并存储为npy\n",
    "\n",
    "ori_img_path = '/media/yinn147/My Passport/2、血吡咯蛋白加合物联合影像组学诊断PAs-HSOS的诊断模型建立与评价（高老师医院课题）/郑州标注/'\n",
    "save_path = '/mnt/ExtData/workspace/pahsos/new_zhengzhou/processed'\n",
    "n = ['GANDUAN2', '111FANDE', 'ganduan']\n",
    "cnt = 1\n",
    "for subfolder in n:\n",
    "    disease_cls_path = os.path.join(ori_img_path, f'{subfolder}/') \n",
    "    patients_path = glob.glob(os.path.join(disease_cls_path, '*'))\n",
    "\n",
    "    for i, patient_path in enumerate(patients_path):\n",
    "\n",
    "        patient_name = patient_path[patient_path.rfind('/')+1:]\n",
    "        dcm_path = glob.glob(os.path.join(patient_path, '*/'))[0]\n",
    "        # print('path', patient_name, patient_path)\n",
    "\n",
    "        patient_save_path = os.path.join(save_path, patient_name)\n",
    "        if not os.path.exists(patient_save_path):\n",
    "            os.makedirs(patient_save_path)\n",
    "\n",
    "        # load img\n",
    "        img, npy_img = read_dcm(dcm_path)\n",
    "        # load label\n",
    "        label_path = glob.glob(os.path.join(patient_path, '*.nii*'))[0]\n",
    "        if len(label_path) == 0:\n",
    "            print(f'cant find label for patient {patient_name}')\n",
    "        # npy_label = sitk.GetArrayFromImage(sitk.ReadImage(label_path))\n",
    "        ## 因为郑州数据的label有的是nii有的是nii.gz 所以这里用nilabel读\n",
    "        npy_label = nib.load(label_path).get_fdata()\n",
    "        npy_label = npy_label.transpose(2, 1, 0)\n",
    "\n",
    "\n",
    "        if npy_img.shape == npy_label.shape:\n",
    "            ## for additional \n",
    "            # if not (patient_name in ('LILINGSHAN', 'MENGXIANLIAN', 'SUNZHIQIANG')):\n",
    "            #     continue\n",
    "            # #load img info\n",
    "            spacing = list(reversed(img.GetSpacing()))\n",
    "            direction = img.GetDirection()\n",
    "            direction = [direction[8], direction[4], direction[0]]\n",
    "\n",
    "            # change label 10 into 10, 11, 12\n",
    "            # if len(np.argwhere(npy_label == 10)) != 81:\n",
    "            #     print(patient_name, len(np.argwhere(npy_label == 10)))\n",
    "            # npy_label = change_label(npy_label)# 原始的，因为有四个有点问题，所以改成下面得了\n",
    "            npy_label = change_label_spe(npy_label, patient_name)\n",
    "\n",
    "            print(f'loading {i}/{len(patients_path)} : {patient_name}  spacing : {spacing} , direction : {direction}, {npy_img.shape}, {npy_label.shape}')\n",
    "            \n",
    "            # preprocess : resample, reorientation\n",
    "            aft_image, _, _ = resample_to_spacing(npy_img, spacing, [1, 1, 1])\n",
    "            aft_label, _, _ = resample_mask_to_spacing(npy_label, spacing, [1, 1, 1], 12)\n",
    "            if direction != [1, 1, 1]:\n",
    "                aft_image = change_axes_of_image(aft_image, direction, [1, 1, 1])\n",
    "                aft_label = change_axes_of_image(aft_label, direction, [1, 1, 1])\n",
    "\n",
    "            print(np.unique(npy_label), len(np.argwhere(npy_label!=0)), np.unique(aft_label), aft_label.shape)\n",
    "\n",
    "            # saving\n",
    "            np.save(os.path.join(patient_save_path, f'{patient_name}_image_ori.npy'), npy_img)\n",
    "            np.save(os.path.join(patient_save_path, f'{patient_name}_image_aft_resample.npy'), aft_image)\n",
    "\n",
    "            np.save(os.path.join(patient_save_path, f'{patient_name}_label_ori.npy'), npy_label)\n",
    "            np.save(os.path.join(patient_save_path, f'{patient_name}_label_aft_resample.npy'), aft_label)\n",
    "            print(f'🔵 {i} / {len(patients_path)} processing and saving npy files : {subfolder} - {patient_name}')\n",
    "        else:\n",
    "            print(f'🔴 {i} / {len(patients_path)} shape error : {subfolder} - {patient_name} ori img: {npy_img.shape}, ori label {npy_label.shape}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里zhouweimeng的mask和label大小不一样，后续已经在simple1以及simple_data中更正，并重新单独处理、生成npy文件"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!!! nibabel读取的需要transpose(2, 1, 0 )才能和sitk读的一样！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 508, 508) (508, 508, 57)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = sitk.GetArrayFromImage(sitk.ReadImage('/media/yinn147/My Passport/2、血吡咯蛋白加合物联合影像组学诊断PAs-HSOS的诊断模型建立与评价（高老师医院课题）/郑州标注/111FANDE/GUOJINLIANG/GUOJINLIANG.nii.gz'))\n",
    "# import nibabel as nib\n",
    "# b = nib.load('/media/yinn147/My Passport/2、血吡咯蛋白加合物联合影像组学诊断PAs-HSOS的诊断模型建立与评价（高老师医院课题）/郑州标注/111FANDE/GUOJINLIANG/GUOJINLIANG.nii.gz').get_fdata()\n",
    "\n",
    "# print(a.shape, b.shape)\n",
    "# len(np.argwhere(b.transpose(2, 1, 0) != a))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. cutting blocks\n",
    "\n",
    "这里 '/mnt/ExtData/pahsos/mask_name.csv' 是之前用于seg处理时，将文件换成test_001_0000.nii.gz格式时的姓名和对应序号关系。这里按照同样的方式遍历，和csv是按顺序一一对应的\n",
    "\n",
    "根据给定的block_size，以及是否使用segmentation作为mask，分别切取12个label对应的block，保存在/preprocess/[cls_type]/[patient_name]/block[block_size]_masked[masked_block0]/中。分别为 1.npy - 12.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1)\n"
     ]
    }
   ],
   "source": [
    "# 做验证使用，确认两者一一对应，不需要跑\n",
    "import pandas as pd\n",
    "\n",
    "match_list = pd.read_csv('mask_name.csv', header=None)\n",
    "match_list = np.array(match_list)\n",
    "print(match_list.shape)\n",
    "\n",
    "preprocessed_npy_path = '/mnt/ExtData/pahsos/Data/preprocessed'\n",
    "masked = True # False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "def resample_to_size(npy_image, target_size, order=1):\n",
    "    source_size = npy_image.shape\n",
    "    scale = np.array(target_size) / source_size\n",
    "    zoom_factor = source_size / np.array(target_size)\n",
    "    target_npy_image = zoom(npy_image, scale, order=order)\n",
    "    return target_npy_image\n",
    "\n",
    "def get_block(img, mask, blocksize=64):\n",
    "    \n",
    "    center = [int(np.mean((np.argwhere(mask != 0))[:, 0])), int(np.mean((np.argwhere(mask != 0))[:, 1])), int(np.mean((np.argwhere(mask != 0))[:, 2]))]\n",
    "    # print(img.shape, center)\n",
    "\n",
    "    block_size = blocksize\n",
    "    block = np.zeros((block_size, block_size, block_size))\n",
    "    \n",
    "    if block_size >= img.shape[0] or block_size >= img.shape[1] or block_size >= img.shape[2]:\n",
    "        print('too big!')\n",
    "        trgt_size_x = max(block_size, img.shape[0])\n",
    "        trgt_size_y = max(block_size, img.shape[1])\n",
    "        trgt_size_z = max(block_size, img.shape[2])\n",
    "        img = resample_to_size(img, (trgt_size_x, trgt_size_y, trgt_size_z))\n",
    "        mask = resample_to_size(mask, (trgt_size_x, trgt_size_y, trgt_size_z))\n",
    "    # else:\n",
    "    ## 处理部分从center取block，会取到外面的情况\n",
    "    if center[0] + int((block_size-1)/2) >= img.shape[0]:\n",
    "        center[0] = img.shape[0] - int((block_size-1)/2) \n",
    "        # print('1')\n",
    "    if center[1] + int((block_size-1)/2) >= img.shape[1]:\n",
    "        center[1] = img.shape[1] - int((block_size-1)/2)\n",
    "        # print('2')\n",
    "    if center[2] + int((block_size-1)/2) >= img.shape[2]:\n",
    "        center[2] = img.shape[2] - int((block_size-1)/2)\n",
    "        # print('3')\n",
    "\n",
    "    if center[0] - int((block_size-1)/2) <= 0:\n",
    "        center[0] = int((block_size-1)/2)\n",
    "        # print('4')\n",
    "    if center[1] - int((block_size-1)/2) <= 0:\n",
    "        center[1] = int((block_size-1)/2)\n",
    "        # print('5')\n",
    "    if center[2] - int((block_size-1)/2) <= 0:\n",
    "        center[2] = int((block_size-1)/2)\n",
    "        # print('6')\n",
    "    \n",
    "    block = img[center[0] - int((block_size-1)/2): center[0] + block_size - int((block_size-1)/2), \n",
    "                center[1] - int((block_size-1)/2): center[1] + block_size - int((block_size-1)/2),\n",
    "                center[2] - int((block_size-1)/2): center[2] + block_size - int((block_size-1)/2)]\n",
    "\n",
    "    return block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 0 / 48 - GUOJINLIANG\n",
      "🔵 1 / 48 - LUFENGDE\n",
      "🔵 2 / 48 - NIUSHUAN3\n",
      "🔵 3 / 48 - WANGXIAOHUA\n",
      "🔵 4 / 48 - XIAOJINZHONG\n",
      "🔵 5 / 48 - XIEDONGMEI\n",
      "🔵 6 / 48 - XIETAO\n",
      "🔵 7 / 48 - XUPENGPENG\n",
      "🔵 8 / 48 - ZHANGXIUHUA\n",
      "🔵 9 / 48 - DINGKOU\n",
      "🔵 10 / 48 - DINGXIZHENG\n",
      "🔵 11 / 48 - FENGZHAOYIN\n",
      "🔵 12 / 48 - GUORUANCHAO\n",
      "🔵 13 / 48 - LIGUOQIANG\n",
      "🔵 14 / 48 - LIJUN\n",
      "🔵 15 / 48 - LILINGSHAN\n",
      "🔵 16 / 48 - LIUXINMIN\n",
      "🔵 17 / 48 - LIUXIUYU\n",
      "🔵 18 / 48 - MALAN\n",
      "🔵 19 / 48 - MAMEILING\n",
      "🔵 20 / 48 - MENGXIANLIAN\n",
      "🔵 21 / 48 - MIAOSHUQIN\n",
      "🔵 22 / 48 - NIUSHUAN\n",
      "🔵 23 / 48 - NIUSHUAN2\n",
      "🔵 24 / 48 - SHIHAIXIA\n",
      "🔵 25 / 48 - SUNYONGXIN\n",
      "🔵 26 / 48 - SUNZHIQIANG\n",
      "🔵 27 / 48 - TIANQUANWU\n",
      "🔵 28 / 48 - WANGHAIXIN\n",
      "🔵 29 / 48 - XUANYUAN\n",
      "🔵 30 / 48 - YANFENGCHAN\n",
      "🔵 31 / 48 - YANGUOQIANG\n",
      "🔵 32 / 48 - ZHANGCHANGHAI\n",
      "🔵 33 / 48 - ZHANGGUANGCHAO\n",
      "🔵 34 / 48 - ZHANGSHENGCAI\n",
      "🔵 35 / 48 - ZHUYOULIANG\n",
      "🔵 36 / 48 - CHENGUITANG\n",
      "🔵 37 / 48 - FANGJIALI\n",
      "🔵 38 / 48 - HANTIEZHU\n",
      "🔵 39 / 48 - JINYUEE\n",
      "🔵 40 / 48 - LIQINGXI\n",
      "🔵 41 / 48 - OUXIANCHEN\n",
      "🔵 42 / 48 - SHIHEWANG\n",
      "🔵 43 / 48 - TONGNANGZI\n",
      "🔵 44 / 48 - YANXIAN\n",
      "🔵 45 / 48 - YUANGONGXIAN\n",
      "🔵 46 / 48 - ZHANGQINGTAO\n",
      "🔵 47 / 48 - ZHANGTINGLIN\n",
      "🔵 0 / 48 - GUOJINLIANG\n",
      "🔵 1 / 48 - LUFENGDE\n",
      "🔵 2 / 48 - NIUSHUAN3\n",
      "🔵 3 / 48 - WANGXIAOHUA\n",
      "🔵 4 / 48 - XIAOJINZHONG\n",
      "🔵 5 / 48 - XIEDONGMEI\n",
      "🔵 6 / 48 - XIETAO\n",
      "🔵 7 / 48 - XUPENGPENG\n",
      "🔵 8 / 48 - ZHANGXIUHUA\n",
      "🔵 9 / 48 - DINGKOU\n",
      "🔵 10 / 48 - DINGXIZHENG\n",
      "🔵 11 / 48 - FENGZHAOYIN\n",
      "🔵 12 / 48 - GUORUANCHAO\n",
      "🔵 13 / 48 - LIGUOQIANG\n",
      "🔵 14 / 48 - LIJUN\n",
      "🔵 15 / 48 - LILINGSHAN\n",
      "🔵 16 / 48 - LIUXINMIN\n",
      "🔵 17 / 48 - LIUXIUYU\n",
      "🔵 18 / 48 - MALAN\n",
      "🔵 19 / 48 - MAMEILING\n",
      "🔵 20 / 48 - MENGXIANLIAN\n",
      "🔵 21 / 48 - MIAOSHUQIN\n",
      "🔵 22 / 48 - NIUSHUAN\n",
      "🔵 23 / 48 - NIUSHUAN2\n",
      "🔵 24 / 48 - SHIHAIXIA\n",
      "🔵 25 / 48 - SUNYONGXIN\n",
      "🔵 26 / 48 - SUNZHIQIANG\n",
      "🔵 27 / 48 - TIANQUANWU\n",
      "🔵 28 / 48 - WANGHAIXIN\n",
      "🔵 29 / 48 - XUANYUAN\n",
      "🔵 30 / 48 - YANFENGCHAN\n",
      "🔵 31 / 48 - YANGUOQIANG\n",
      "🔵 32 / 48 - ZHANGCHANGHAI\n",
      "🔵 33 / 48 - ZHANGGUANGCHAO\n",
      "🔵 34 / 48 - ZHANGSHENGCAI\n",
      "🔵 35 / 48 - ZHUYOULIANG\n",
      "🔵 36 / 48 - CHENGUITANG\n",
      "🔵 37 / 48 - FANGJIALI\n",
      "🔵 38 / 48 - HANTIEZHU\n",
      "🔵 39 / 48 - JINYUEE\n",
      "🔵 40 / 48 - LIQINGXI\n",
      "🔵 41 / 48 - OUXIANCHEN\n",
      "🔵 42 / 48 - SHIHEWANG\n",
      "🔵 43 / 48 - TONGNANGZI\n",
      "🔵 44 / 48 - YANXIAN\n",
      "🔵 45 / 48 - YUANGONGXIAN\n",
      "🔵 46 / 48 - ZHANGQINGTAO\n",
      "🔵 47 / 48 - ZHANGTINGLIN\n",
      "🔵 0 / 48 - GUOJINLIANG\n",
      "🔵 1 / 48 - LUFENGDE\n",
      "🔵 2 / 48 - NIUSHUAN3\n",
      "🔵 3 / 48 - WANGXIAOHUA\n",
      "🔵 4 / 48 - XIAOJINZHONG\n",
      "🔵 5 / 48 - XIEDONGMEI\n",
      "🔵 6 / 48 - XIETAO\n",
      "🔵 7 / 48 - XUPENGPENG\n",
      "🔵 8 / 48 - ZHANGXIUHUA\n",
      "🔵 9 / 48 - DINGKOU\n",
      "🔵 10 / 48 - DINGXIZHENG\n",
      "🔵 11 / 48 - FENGZHAOYIN\n",
      "🔵 12 / 48 - GUORUANCHAO\n",
      "🔵 13 / 48 - LIGUOQIANG\n",
      "🔵 14 / 48 - LIJUN\n",
      "🔵 15 / 48 - LILINGSHAN\n",
      "🔵 16 / 48 - LIUXINMIN\n",
      "🔵 17 / 48 - LIUXIUYU\n",
      "🔵 18 / 48 - MALAN\n",
      "🔵 19 / 48 - MAMEILING\n",
      "🔵 20 / 48 - MENGXIANLIAN\n",
      "🔵 21 / 48 - MIAOSHUQIN\n",
      "🔵 22 / 48 - NIUSHUAN\n",
      "🔵 23 / 48 - NIUSHUAN2\n",
      "🔵 24 / 48 - SHIHAIXIA\n",
      "🔵 25 / 48 - SUNYONGXIN\n",
      "🔵 26 / 48 - SUNZHIQIANG\n",
      "🔵 27 / 48 - TIANQUANWU\n",
      "🔵 28 / 48 - WANGHAIXIN\n",
      "🔵 29 / 48 - XUANYUAN\n",
      "🔵 30 / 48 - YANFENGCHAN\n",
      "🔵 31 / 48 - YANGUOQIANG\n",
      "🔵 32 / 48 - ZHANGCHANGHAI\n",
      "🔵 33 / 48 - ZHANGGUANGCHAO\n",
      "🔵 34 / 48 - ZHANGSHENGCAI\n",
      "🔵 35 / 48 - ZHUYOULIANG\n",
      "🔵 36 / 48 - CHENGUITANG\n",
      "🔵 37 / 48 - FANGJIALI\n",
      "🔵 38 / 48 - HANTIEZHU\n",
      "🔵 39 / 48 - JINYUEE\n",
      "🔵 40 / 48 - LIQINGXI\n",
      "🔵 41 / 48 - OUXIANCHEN\n",
      "🔵 42 / 48 - SHIHEWANG\n",
      "🔵 43 / 48 - TONGNANGZI\n",
      "🔵 44 / 48 - YANXIAN\n",
      "🔵 45 / 48 - YUANGONGXIAN\n",
      "🔵 46 / 48 - ZHANGQINGTAO\n",
      "🔵 47 / 48 - ZHANGTINGLIN\n",
      "🔵 0 / 48 - GUOJINLIANG\n",
      "🔵 1 / 48 - LUFENGDE\n",
      "🔵 2 / 48 - NIUSHUAN3\n",
      "🔵 3 / 48 - WANGXIAOHUA\n",
      "🔵 4 / 48 - XIAOJINZHONG\n",
      "🔵 5 / 48 - XIEDONGMEI\n",
      "🔵 6 / 48 - XIETAO\n",
      "🔵 7 / 48 - XUPENGPENG\n",
      "🔵 8 / 48 - ZHANGXIUHUA\n",
      "🔵 9 / 48 - DINGKOU\n",
      "🔵 10 / 48 - DINGXIZHENG\n",
      "🔵 11 / 48 - FENGZHAOYIN\n",
      "🔵 12 / 48 - GUORUANCHAO\n",
      "🔵 13 / 48 - LIGUOQIANG\n",
      "🔵 14 / 48 - LIJUN\n",
      "🔵 15 / 48 - LILINGSHAN\n",
      "🔵 16 / 48 - LIUXINMIN\n",
      "🔵 17 / 48 - LIUXIUYU\n",
      "🔵 18 / 48 - MALAN\n",
      "🔵 19 / 48 - MAMEILING\n",
      "🔵 20 / 48 - MENGXIANLIAN\n",
      "🔵 21 / 48 - MIAOSHUQIN\n",
      "🔵 22 / 48 - NIUSHUAN\n",
      "🔵 23 / 48 - NIUSHUAN2\n",
      "🔵 24 / 48 - SHIHAIXIA\n",
      "🔵 25 / 48 - SUNYONGXIN\n",
      "🔵 26 / 48 - SUNZHIQIANG\n",
      "🔵 27 / 48 - TIANQUANWU\n",
      "🔵 28 / 48 - WANGHAIXIN\n",
      "🔵 29 / 48 - XUANYUAN\n",
      "🔵 30 / 48 - YANFENGCHAN\n",
      "🔵 31 / 48 - YANGUOQIANG\n",
      "🔵 32 / 48 - ZHANGCHANGHAI\n",
      "🔵 33 / 48 - ZHANGGUANGCHAO\n",
      "🔵 34 / 48 - ZHANGSHENGCAI\n",
      "🔵 35 / 48 - ZHUYOULIANG\n",
      "🔵 36 / 48 - CHENGUITANG\n",
      "🔵 37 / 48 - FANGJIALI\n",
      "🔵 38 / 48 - HANTIEZHU\n",
      "🔵 39 / 48 - JINYUEE\n",
      "🔵 40 / 48 - LIQINGXI\n",
      "🔵 41 / 48 - OUXIANCHEN\n",
      "🔵 42 / 48 - SHIHEWANG\n",
      "🔵 43 / 48 - TONGNANGZI\n",
      "🔵 44 / 48 - YANXIAN\n",
      "🔵 45 / 48 - YUANGONGXIAN\n",
      "🔵 46 / 48 - ZHANGQINGTAO\n",
      "🔵 47 / 48 - ZHANGTINGLIN\n"
     ]
    }
   ],
   "source": [
    "# CROP BLOCK\n",
    "preprocessed_npy_path = '/mnt/ExtData/workspace/pahsos/new_zhengzhou/processed'\n",
    "#这里默认保存在原始preprocess的文件夹中\n",
    "seg_output_path = '/mnt/ExtData/workspace/pahsos/new_zhengzhou/segmentation/output'\n",
    "\n",
    "masked_block = True # False\n",
    "block_sizes = [64, 96, 128, 160]\n",
    "\n",
    "for block_size in block_sizes:\n",
    "    seg_output_list = sorted(glob.glob(os.path.join(seg_output_path, '*nii.gz')))\n",
    "\n",
    "    # patient_path = np.sort(glob.glob(os.path.join(preprocessed_npy_path, '*')))\n",
    "\n",
    "    for patient_idx in range(match_list.shape[0]):     \n",
    "\n",
    "        patient_path = os.path.join(preprocessed_npy_path, match_list[patient_idx][0])  \n",
    "        # 创建block保存文件夹\n",
    "        block_save_path = os.path.join(patient_path, f'block{block_size}_masked{masked_block}_new')\n",
    "        if not os.path.exists(block_save_path):\n",
    "            os.makedirs(block_save_path)\n",
    "        \n",
    "        patient_name = match_list[patient_idx][0]\n",
    "\n",
    "        # if os.path.exists(os.path.join(block_save_path, f'{i}.npy')):\n",
    "        #     print(f'already process {patient_name}')\n",
    "        #     continue\n",
    "\n",
    "        seg_nii_path = seg_output_list[patient_idx]\n",
    "        img_npy_path = os.path.join(patient_path, f'{patient_name}_image_aft_resample.npy')\n",
    "        mask_npy_path = os.path.join(patient_path, f'{patient_name}_label_aft_resample.npy')\n",
    "\n",
    "        seg = sitk.GetArrayFromImage(sitk.ReadImage(seg_nii_path))\n",
    "\n",
    "        seg[seg>=1] = 1\n",
    "        img = np.load(img_npy_path)\n",
    "        mask = np.load(mask_npy_path)\n",
    "\n",
    "        if seg.shape != img.shape or img.shape != mask.shape or seg.shape != mask.shape:\n",
    "            print(f'🔴 {patient_idx} / {len(patient_path)} shape error : {patient_name} seg : {seg.shape} img : {img.shape}, ori label : {mask.shape}')\n",
    "        else:\n",
    "            \n",
    "            if masked_block:\n",
    "                img = img * seg\n",
    "\n",
    "            for i in range(1, len(np.unique(mask))):\n",
    "                one_label = np.zeros(mask.shape)\n",
    "                one_label[mask==i] = 1\n",
    "                if len(np.argwhere(one_label != 0)) == 0:\n",
    "                    print(f'🔴 {patient_idx} / {match_list.shape[0]} - {patient_name} mask {i} error')\n",
    "                else:\n",
    "                    block = get_block(img, one_label, block_size)\n",
    "                    np.save(os.path.join(block_save_path, f'{i}.npy'), block)\n",
    "            if i == len(np.unique(mask))-1:\n",
    "                print(f'🔵 {patient_idx} / {match_list.shape[0]} - {patient_name}')\n",
    "            else:\n",
    "                print(f'please check mask {np.unique(mask)}')\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a49f9f554ccb72680b8efe31fc9ef91aa23f2b45d37b4fdbf69982e4b3da32d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
